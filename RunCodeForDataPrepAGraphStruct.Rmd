---
title: "Run code to produce data CSV and graph stats"
author: "Jonathan Bourne"
date: "26 March 2016"
output: html_document
---



```{r load_packages}
packages <- c("dplyr", "tidyr", "ggplot2", "caret", "corrplot", "xtable", "magrittr", "zoo", "igraph", "rgexf", "MCL", "Hmisc", "gridExtra", "xtable", "lubridate")
sapply(packages, library, character.only = TRUE)


basewd <- "C:/Users/Jonno/Dropbox/Data_Analytics" #change this to your dropbox file path for data analytics
DataFiles <- file.path(basewd, "Data")
GraphicsFiles <- file.path(basewd, "Graphics", "Milestone3")

```



```{r load_data}
setwd(DataFiles)
TwitRetweets <- read.csv(gzfile("twitter_withretweets_daily.csv.gz"), as.is = TRUE)
symbology <- read.csv("symbology.csv")
setwd(GraphicsFiles)
```

#Data Preparation


```{r }
startDate = "1/1/2011" %>% dmy
endDate = "31/12/2015" %>% dmy


#Create a data frame grouping months by period size
groupdata = data.frame(Months = seq(startDate, endDate, "months")) %>% 
  mutate(group =( 1+(1:nrow(.)))/2) %>% mutate(group = floor(group))


TwitRetweets %<>% mutate(TIMESTAMP_UTC = ymd_hms(TIMESTAMP_UTC)) %>%  
  filter(TIMESTAMP_UTC > startDate, TIMESTAMP_UTC < endDate)

```

```{r}
#viable rows data
viable <- colSums(TwitBull>0) / nrow(TwitBull) > 5/7

#Create a data frame grouping months by period size
groupdata = data.frame(Months = seq(startDate, endDate, "months")) %>% 
  mutate(group =( 1+(1:nrow(.)))/2) %>% mutate(group = floor(group))
```

```{r}
TwitMatList <-function(TweetDataRaw, Metric = "BULLISH_INTENSITY",groupdata){
  TwitBull = TweetDataRaw %>% select_("SYMBOL", "TIMESTAMP_UTC", Metric) %>% 
    rename_("Metric" = Metric) %>% 
    spread(key = SYMBOL, value = Metric, fill = 0) %>% 
    mutate(TIMESTAMP_UTC = as.Date(TIMESTAMP_UTC))
  
  print("Metric select data set reshaped")
  
  viable = colSums(TwitBull>0) / nrow(TwitBull) > 5/7
  TwitBullvar = TwitBull[,viable]
  TwitBullvar %<>%  filter(TIMESTAMP_UTC > as.Date("2010-12-31"),TIMESTAMP_UTC < as.Date("2016-01-01") )
  
  print("Non-Viable symbols removed")
  
  #create a vector of period groups
  rowIndex <- match(as.yearmon(TwitBullvar$TIMESTAMP_UTC) , as.yearmon(groupdata[,1]))
  periodID <- groupdata[rowIndex,2]
  NumPeriods <- 1:max(groupdata[,2])

  TwitMatList <- lapply(NumPeriods, function(n) {
  
    data = TwitBullvar[periodID == n,]
    remove = nearZeroVar(data)
    if(length(remove) >0){
    data = data[,-remove]
    }
    corlist = data[,2:ncol(data)] %>% as.matrix %>% rcorr
    distmat = sqrt(2*(1-corlist[[1]]))
    sigmat = (1-corlist[[3]])>0.95
    #sigmat[sigmat == FALSE] <- NA #changing to NA's means that the clustering doesn't work
    MNet = distmat*sigmat #weighted undirected adjacency matrix
    MNet = 2-MNet
    MNet[MNet == 2] = 0
    #MNet = graph.adjacency(MNet, mode = "undirected", weighted = TRUE, diag = FALSE)#do not use if clustering with mcl
    com5 = mcl(x = MNet, addLoops=TRUE, max.iter = 100,inflation = 2 , ESM = FALSE, allow1 = TRUE)
    symclust = data.frame(SYMBOL = names(data)[-1], ClusterID = com5$Cluster)
    Twitaggmat = TweetDataRaw %>% select_("SYMBOL", "TIMESTAMP_UTC", Metric) %>% 
      inner_join(., symclust, "SYMBOL")
    print(paste("Period",n, "complete"))
    Twitaggmat
    
    }
  )

}

```


Function: Aggregate list into unweighted time periods and combine into single dataframe
```{r}
Aggregator <- function(TwitMatList, Metric){
  TwitMatAgg<- lapply(1:length(TwitMatList), function(m) {
    #SUmmary uses non-standard evaluation so that the Metric can be properly evaluated using it's name
  x <- TwitMatList[[m]] %>% group_by(ClusterID) %>% summarise_(mean = (paste("mean(", Metric,")"))) %>% ungroup
   x2 <- TwitMatList[[m]] %>% group_by(SYMBOL) %>% 
     summarise(ClusterID = first(ClusterID)) %>% left_join(., x, by = "ClusterID") %>%
     mutate(PeriodID = m)
  }
  )
  TwitMatAgg <- rbind_all(TwitMatAgg)
}


```



Structure graph for use in gephi with as much metadata as possible
symbol, cluster ID, edge type (aka inter cluster vs intra cluster), is target symbol/node yesy/no etc

```{r}
graphmakeR <- function(data, maindat = TwitRetweets, Metric, groupdata, Periodnum){

#create a vector of period groups
rowIndex <- match(as.yearmon(data$TIMESTAMP_UTC) , as.yearmon(groupdata[,1]))
periodID <- groupdata[rowIndex,2]
  
  data = data[periodID == Periodnum,]
  
  remove = nearZeroVar(data)
  if(length(remove) >0){
  data = data[,-remove]
  }
    print("Near zero varience removed")
    
    corlist = data[,2:ncol(data)] %>% as.matrix %>% rcorr
    distmat = sqrt(2*(1-corlist[[1]]))
    
    print("Distance matrix complete")
    sigmat = (1-corlist[[3]])>0.95
    #sigmat[sigmat ==5] <- NA
    MNet = distmat*sigmat #weighted undirected adjacency matrix
    MNet = 2-MNet
    MNet[MNet == 2] = 0
    print("Weighted undirected matrix complete")
    
  #MNet = graph.adjacency(MNet, mode = "undirected", weighted = TRUE, diag = FALSE)#do not use if clustering with mcl
  MNet2 <- MNet
  com5 = mcl(x = MNet2, addLoops=TRUE, ESM = FALSE)
  symclust = data.frame(SYMBOL = names(data)[-1], ClusterID = com5$Cluster)
  TwitMatAgg = maindat %>% select_("SYMBOL", "TIMESTAMP_UTC", Metric) %>% 
  rename_("Metric" = Metric) %>% 
    inner_join(., symclust, "SYMBOL")

  print("Clusters Identified")

  MNet = graph.adjacency(MNet, mode = "undirected", weighted = TRUE, diag = FALSE)#do not use if   
  print("Graph object generated")
  MNet <- set.vertex.attribute(MNet, name = "Cluster", index = V(MNet), value = com5$Cluster)
  list.vertex.attributes(MNet)


noclust <-4
#colour nodes by cluster
test <- table(com5$Cluster) %>% data.frame %>% rename(ClusterID = Var1, Nodes = Freq) %>%
  mutate(rank = rank(-Nodes, ties.method = "min"), 
         rank = ifelse(ClusterID==0,1000,rank-1),
         colour = "None", 
         colour = ifelse(Nodes >noclust,"small", colour),
         colour = ifelse(ClusterID==0,"None",colour),
         colour =  ifelse(rank ==1 & Nodes >noclust, "first", colour), 
         colour = ifelse(rank == 2 & Nodes >noclust, "second", colour), 
         colour = ifelse(rank == 3 & Nodes >noclust, "third", colour))


V(MNet)$fill<-test$colour[match(com5$Cluster,test$ClusterID)]

rowIndex <- match(as.yearmon(TwitMatAgg$TIMESTAMP_UTC) , as.yearmon(groupdata[,1]))
TwitperiodID <- groupdata[rowIndex,2]


Perclusts <- TwitMatAgg %>% filter(TwitperiodID == Periodnum) %>% select(SYMBOL, ClusterID) 
Perclusts2 <- Perclusts %>% rename(SYMBOL2 = SYMBOL)
edgecolours <-get.edgelist(MNet) %>% data.frame %>% rename(SYMBOL = X1, SYMBOL2 = X2) %>%
  left_join(., Perclusts, by = "SYMBOL") %>%left_join(., Perclusts2, by = "SYMBOL2") %>%
  mutate(colour = ifelse(ClusterID.x == ClusterID.y, "00,255,00", "194,194,194"))

E(MNet)$colour <- edgecolours$colour
MNet
}
```



Create a list of all time periods for all metrics to compare the number of clusters
```{r}

MetricList <- lapply(c(4:5,7:9), function(z){
  Score <- TwitMatList(TwitRetweets, Metric = names(TwitRetweets)[z], groupdata)
x <- Aggregator(Score, Metric = names(TwitRetweets)[z])
}
                     )
names(MetricList) <-names(TwitRetweets)[c(4:5,7:9)]
setwd(DataFiles)
saveRDS(MetricList, "MetricList.rds")

lapply(1:length(MetricList), function(n){
  write.csv(MetricList[[n]], file = paste(names(MetricList[n]), ".csv", sep=""))
})


```



Extract number of clusters period
```{r}

x <- sapply(1:5, function(n){
  x <- MetricList[[n]] %>% group_by(PeriodID) %>% 
    summarise(TotalClusters = length(unique(ClusterID))) %>% ungroup %>%
    select(TotalClusters) 
    names(x) <- names(MetricList[n])
    x
    }
)

ClusterPeriod <- do.call(cbind, x) %>% as.data.frame %>% mutate(PeriodID = 1:nrow(.)) %>%
  gather(key = Metric, value=Clusters, -PeriodID)
```




```{r}
graphstats <- data.frame(matrix(NA, nrow = 30, ncol = 6))
names(graphstats) = c("Period","Degree","Clustering", "Diameter", "BetweenessMean", "BetweennessMedian")
graphstats %<>% mutate(Period = 1:30)


graphstat_metric <-lapply(c(4:5,7:9), function(z){
      Metric = names(TwitRetweets)[z]
      
      TwitBull = TwitRetweets %>% select_("SYMBOL", "TIMESTAMP_UTC", Metric) %>% 
        rename_("Metric" = Metric) %>% 
        spread(key = SYMBOL, value = Metric, fill = 0) %>% 
        mutate(TIMESTAMP_UTC = as.Date(TIMESTAMP_UTC))
      
      print("Metric select data set reshaped")
      
      viable = colSums(TwitBull>0) / nrow(TwitBull) > 5/7
      TwitBullvar = TwitBull[,viable]
      TwitBullvar %<>%  filter(TIMESTAMP_UTC > as.Date("2010-12-31"),
                               TIMESTAMP_UTC < as.Date("2016-01-01") )
    
      for (i in 1:30){
      graf <- graphmakeR(data = TwitBullvar, maindat = TwitRetweets, 
                         Metric, groupdata,  Periodnum = i )
        graphstats[i,-1] <- c(degree(graf) %>% mean, 
                              transitivity(graf), #graph Clustering Coefficient
                              diameter(graf), #graph diamter
                              betweenness(graf) %>% mean,
                              betweenness(graf) %>% median)
        print(paste("period", i))
      }
      graphstats %<>% mutate(Metric = Metric)
      }
    )

graphstat_metric <- bind_rows(graphstat_metric) 
graphstat_metric %<>% rename(PeriodID = Period) %>% 
  left_join(.,ClusterPeriod, by = c("PeriodID", "Metric")) %>% 
  rename(Cluster_Count = Clusters) %>% filter(Metric != "BULL_SCORED_MESSAGES", 
                                              Metric != "BEAR_SCORED_MESSAGES")

setwd(DataFiles)
write.csv(graphstat_metric, "graphstat_metric.csv", row.names=FALSE)

```



```{r}
#sink("Rpackages.bib")
n <-sapply(names(sessionInfo()$otherPkgs), 
    function(x) print(citation(x), style = "Bibtex"))
```

