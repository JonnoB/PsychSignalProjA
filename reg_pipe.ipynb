{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random as r\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Quandl as q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sym</th>\n",
       "      <th>date</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3551142</th>\n",
       "      <td>NUAN</td>\n",
       "      <td>2012-04-04 04:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667150</th>\n",
       "      <td>BOH</td>\n",
       "      <td>2013-03-22 04:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767276</th>\n",
       "      <td>EWJ</td>\n",
       "      <td>2013-04-21 04:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855904</th>\n",
       "      <td>CCMP</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092424</th>\n",
       "      <td>GED</td>\n",
       "      <td>2014-04-28 04:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sym                date  cluster\n",
       "3551142  NUAN 2012-04-04 04:00:00        3\n",
       "667150    BOH 2013-03-22 04:00:00        2\n",
       "1767276   EWJ 2013-04-21 04:00:00        4\n",
       "855904   CCMP 2013-01-01 05:00:00        2\n",
       "2092424   GED 2014-04-28 04:00:00        3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a sample\n",
    "path=\"C:\\\\dev\\\\psignal\\\\data\\\\\"\n",
    "pureTwt='twitter_noretweets_daily.csv'\n",
    "ptwt=pd.read_csv(filepath_or_buffer=path+pureTwt,delimiter=\",\",header=0)\n",
    "ptwt=ptwt.sample(n=1000)\n",
    "ptwt['TIMESTAMP_UTC']=pd.to_datetime(arg=ptwt.TIMESTAMP_UTC,infer_datetime_format='true',unit='D')\n",
    "#ptwt['TIMESTAMP_UTC']=pd.to_datetime(arg=ptwt.TIMESTAMP_UTC,format='%Y%m%d')\n",
    "cols=['SYMBOL','TIMESTAMP_UTC']\n",
    "ptwt=ptwt.reindex(columns=cols)\n",
    "ptwt.columns=['sym','date']\n",
    "ptwt['cluster']=r.randint(low=1,high=5,size=len(ptwt))\n",
    "ptwt.to_csv(\"sample ptwt.csv\")\n",
    "#this is how data should look like after clustring\n",
    "ptwt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'set_freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a29de5e5c25d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msampleTWT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sample ptwt.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mptwt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msampleTWT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mptwt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2358\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 2360\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   2361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'set_freq'"
     ]
    }
   ],
   "source": [
    "#if sample already exists use this to import it\n",
    "sampleTWT='sample ptwt.csv'\n",
    "ptwt=pd.read_csv(filepath_or_buffer=path+sampleTWT,delimiter=\",\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data is imported from clustering stage\n",
    "data = pd.csv_read('../data/data2010to2015.csv')\n",
    "#format is: date | sym  | cluster\n",
    "#date is daily\n",
    "#sym is cashtag/ticker\n",
    "#cluster is a number that indicates cluster\n",
    "\n",
    "tickers = data['sym'].unique()\n",
    "rdata=pd.DataFrame({})\n",
    "for sym in tickers:   \n",
    "    try:\n",
    "        #can later expand this to include search from other db than WIKI\n",
    "        tmp=q.get(\"WIKI/\"+sym+\".11\",start='2010-01-01', end='2016-01-01', transformation='rdiff')\n",
    "        tmp[sym]=sym\n",
    "    except:\n",
    "        tmp= #NaNs dataframe\n",
    "    rdata=pd.concat(rdata,tmp)\n",
    "\n",
    "\n",
    "mi = pd.read_csv('../data/sp500.csv')\n",
    "\n",
    "data = data.set_index(data['date'])\n",
    "\n",
    "mi = mi.set_index(pd.to_datetime(mi['Date']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-83b1dcba6234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    810\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m                        copy=copy)\n\u001b[0m\u001b[0;32m    813\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    825\u001b[0m             raise TypeError('first argument must be an iterable of pandas '\n\u001b[0;32m    826\u001b[0m                             \u001b[1;34m'objects, you passed an object of type '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m                             '\"{0}\"'.format(type(objs).__name__))\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'outer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "a=pd.DataFrame({})\n",
    "b=pd.DataFrame({'a':['2','3']})\n",
    "pd.concat(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>-0.078026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>0.921009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>-0.569918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.352940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1.514005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    return\n",
       "0 2010-01-01 -0.078026\n",
       "1 2010-01-02  0.921009\n",
       "2 2010-01-03 -0.569918\n",
       "3 2010-01-04  0.352940\n",
       "4 2010-01-05  1.514005"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500=pd.DataFrame({'date':pd.date_range(start='2010-01-01',end='2015-12-31',frequency=\"D\"),\\\n",
    "                    'return':r.randn(len(pd.date_range(start='2010-01-01',end='2015-12-31',frequency=\"D\")))})\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-01'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows=pd.period_range(start='2010',end='2015',freq=\"M\")\n",
    "windows=windows.format()\n",
    "windows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import <regression> as reg\n",
    "for stock in ptwt['sym'].unique():\n",
    "    for window_end_idx in range(1,len(windows)):\n",
    "        mask=(ptwt['sym']==stock)&(ptwt['date']>=windows[window_end_idx-1])&(ptwt['date']<windows[window_end_idx])\n",
    "        tmp=ptwp[mask]\n",
    "        r_t_plus_one=tmp['return'].ix[1:]\n",
    "        r_t=tmp['return'].ix[0:len(tmp)-1]\n",
    "        mask_market_index=(ptwt['date']>=windows[window_end_idx-1])&(ptwt['date']<windows[window_end_idx])\n",
    "        market_index=SP500[mask].ix[0:len(tmp)-1] #check and correct for stationarity\n",
    "        SIR=ptwt[mask_market_index].groupby('cluster','date').mean() #compute mean return for each day and cluster\n",
    "        stationarity_test=reg.adftest(r_t_plus_one, kind=\"c\")\n",
    "        while (stationarity_test):\n",
    "            r_t_plus_one=reg.takeFirstDifference(r_t_plus_one)\n",
    "            r_t=reg.takeFirstDifference(r_t)\n",
    "            stationarity_test=reg.adftest(r_t_plus_one, kind=\"c\")\n",
    "        tmp_reg=reg.GLS(y=r_t_plus_one,x=[r_t,market_index],include_constant=True,return_residuals=True)\n",
    "        tmp_reg_prime=reg.GLS(y=tmp_reg.residuals,x=[r_t,SIR],include_constant=True,return_residuals=True)\n",
    "        regression[(stock, window)]=(tmp_reg,tmp_reg_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sym</th>\n",
       "      <th>date</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALE</td>\n",
       "      <td>2015-01-16 05:00:00</td>\n",
       "      <td>1.54638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sym                date   return\n",
       "3  ALE 2015-01-16 05:00:00  1.54638"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=(ptwt['sym']=='ALE')&(ptwt['date']>='2015-1')&(ptwt['date']<='2015-12')\n",
    "ptwt[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
