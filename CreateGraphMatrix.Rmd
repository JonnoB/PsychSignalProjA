---
title: "Retweets Absolute Bulllisness Adjacency"
author: "Jonathan Bourne"
date: "23 February 2016"
output: html_document
---


```{r}
packages <- c("dplyr", "tidyr", "ggplot2", "caret", "corrplot", "xtable", "magrittr", "zoo", "igraph", "rgefx")
sapply(packages, library, character.only = TRUE)


basewd <- "C:/Users/Jonno/Dropbox/Data_Analytics" #change this to your dropbox file path for data analytics
DataFiles <- file.path(basewd, "Data")
GraphicsFiles <- file.path(basewd, "Graphics", "Milestone2")

```


Import data
```{r}
setwd(DataFiles)
TwitRetweets <- read.csv(gzfile("twitter_withretweets_daily.csv.gz"), as.is = TRUE)
symbology <- read.csv("symbology.csv")
setwd(GraphicsFiles)
```

#Data Preparation

Reshape the twitter data into wide form, remove weekends and holidays?
```{r}
TwitBull <- TwitRetweets %>% select(SYMBOL, TIMESTAMP_UTC, BULL_SCORED_MESSAGES) %>% 
  spread(key = SYMBOL, value = BULL_SCORED_MESSAGES, fill = 0) #change metric
setwd(DataFiles)

```


Remove variables of near zero variance. Save as csv
```{r}
x1 <-nearZeroVar(TwitBull)
TwitBullvar <- TwitBull[,-x1]
TwitBullvar %<>% mutate(TIMESTAMP_UTC = as.Date(TIMESTAMP_UTC))

#write.csv(TwitBull, file = "TwitBullWide.csv") #save under new type with correct metric

```


Seperate into time periods and create a single test time period
```{r}
periodID <- rep(1:ceiling(nrow(TwitBullvar)/60), length.out = nrow(TwitBullvar), each = 60)

testeriod <- 27

data <- TwitBullvar[periodID == testeriod,]
DataZeroVar <- nearZeroVar(data)
```

Decompose to enforce stationarity in each timeseries, this will create a large list of decomposed data. Also create a matrix/matrices of the decomposed data.
```{r}
#  <- lapply(data, function(n) {
#   
# })

x <- ts(data[,2], frequency = 7 )
x <- stats::decompose(x)
```

We didn't remove the trend because over a two month period there is not enough time for changes in twitter volume and so removing any apparent trend could be more related to major events than any general trend

Create distance and significance matrices
```{r}
corlist <- data2[,2:ncol(data2)] %>% as.matrix %>% rcorr
distmat <- sqrt(2*(1-corlist[[1]]))

#number of links for given significance value
cutoff <- data.frame(cutoff = seq(0.75,1,0.01), edges = NA)

cutoff$edges <- sapply(cutoff$cutoff ,function(n) {
  sum(corlist[[3]]>n, na.rm = TRUE)/2
  })

ggplot(cutoff, aes(x= cutoff, y= edges)) + geom_line() +ggtitle("Edges decreast Linearly with increaing cutoff point")
```

Merge Distance and Adjacency matrices to create a weighted undirected graph
```{r}
MNet <- distmat*(corlist[[3]]>0.95) #weighted undirected adjacency matrix
MNet <- graph.adjacency(MNet, mode = "undirected", weighted = TRUE, diag = FALSE)

fc <- fastgreedy.community(MNet)

```

Structure graph for use in gephi with as much metadata as possible
symbol, cluster ID, edge type (aka inter cluster vs intra cluster), is target symbol/node yesy/no etc
```{r}

```
